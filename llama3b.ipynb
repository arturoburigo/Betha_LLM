{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "880760c2bb2e461b80f65ad5ce35d10c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "The model did not return a loss from the inputs, only the following keys: logits,past_key_values. For reference, the inputs it received are input_ids,attention_mask.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 253\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, tokenizer\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 253\u001b[0m     model, tokenizer \u001b[38;5;241m=\u001b[39m main()\n",
      "Cell \u001b[1;32mIn[4], line 248\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# Treina o modelo com todo o conhecimento\u001b[39;00m\n\u001b[0;32m    247\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-3.2-3B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 248\u001b[0m model, tokenizer \u001b[38;5;241m=\u001b[39m train_model(model_name, knowledge_manager\u001b[38;5;241m.\u001b[39mknowledge_base)\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, tokenizer\n",
      "Cell \u001b[1;32mIn[4], line 130\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model_name, knowledge_base, output_dir)\u001b[0m\n\u001b[0;32m    123\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m    124\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    125\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m    126\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[0;32m    127\u001b[0m )\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# Treina o modelo\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# Salva o modelo e tokenizer\u001b[39;00m\n\u001b[0;32m    133\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(output_dir)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:2122\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2120\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   2123\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   2124\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[0;32m   2125\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[0;32m   2126\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[0;32m   2127\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:2474\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2471\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   2473\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 2474\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[0;32m   2476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2477\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2478\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2479\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2480\u001b[0m ):\n\u001b[0;32m   2481\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2482\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:3572\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   3571\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 3572\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs, num_items_in_batch\u001b[38;5;241m=\u001b[39mnum_items_in_batch)\n\u001b[0;32m   3574\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[0;32m   3575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3576\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3577\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3578\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:3646\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3644\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3645\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m outputs:\n\u001b[1;32m-> 3646\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3647\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model did not return a loss from the inputs, only the following keys: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3648\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(outputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. For reference, the inputs it received are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(inputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3649\u001b[0m         )\n\u001b[0;32m   3650\u001b[0m     \u001b[38;5;66;03m# We don't use .loss here since the model may return tuples instead of ModelOutput.\u001b[39;00m\n\u001b[0;32m   3651\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: The model did not return a loss from the inputs, only the following keys: logits,past_key_values. For reference, the inputs it received are input_ids,attention_mask."
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "class KnowledgeBaseDataset(Dataset):\n",
    "    def __init__(self, knowledge_base, tokenizer, max_length=512):\n",
    "        self.examples = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Processa a base de conhecimento em formato de exemplos de treino\n",
    "        for category, qa_pairs in knowledge_base[\"perguntas_respostas\"].items():\n",
    "            if isinstance(qa_pairs, dict):\n",
    "                # Formata cada par de pergunta/resposta como um exemplo de treino\n",
    "                question = qa_pairs.get(\"pergunta\", \"\")\n",
    "                answer = self._format_answer(qa_pairs.get(\"resposta\", {}))\n",
    "                \n",
    "                if question and answer:\n",
    "                    self.examples.append(self._format_example(question, answer))\n",
    "                \n",
    "                # Se houver exemplos de código, adiciona como exemplos separados\n",
    "                if \"exemplos\" in qa_pairs:\n",
    "                    for context, code in qa_pairs[\"exemplos\"].items():\n",
    "                        question = f\"Mostre um exemplo de código para {context}\"\n",
    "                        self.examples.append(self._format_example(question, code))\n",
    "\n",
    "    def _format_answer(self, answer):\n",
    "        if isinstance(answer, dict):\n",
    "            # Formata respostas estruturadas\n",
    "            formatted = []\n",
    "            for key, value in answer.items():\n",
    "                if isinstance(value, list):\n",
    "                    formatted.append(f\"{key}:\\n\" + \"\\n\".join(f\"- {item}\" for item in value))\n",
    "                else:\n",
    "                    formatted.append(f\"{key}: {value}\")\n",
    "            return \"\\n\".join(formatted)\n",
    "        return str(answer)\n",
    "\n",
    "    def _format_example(self, question, answer):\n",
    "        # Formato do prompt: pergunta e resposta com marcadores específicos\n",
    "        prompt = f\"\"\"###Pergunta\n",
    "{question}\n",
    "\n",
    "###Resposta\n",
    "{answer}\n",
    "\n",
    "###Fim\"\"\"\n",
    "        return prompt\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Tokeniza o exemplo com padding e truncamento\n",
    "        encodings = self.tokenizer(\n",
    "            self.examples[idx],\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": encodings[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": encodings[\"attention_mask\"].squeeze()\n",
    "        }\n",
    "\n",
    "class KnowledgeManager:\n",
    "    def __init__(self, base_path=\"knowledge_base\"):\n",
    "        self.base_path = base_path\n",
    "        self.knowledge_base = self._load_knowledge()\n",
    "        os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "    def _load_knowledge(self):\n",
    "        # Carrega todos os arquivos de conhecimento\n",
    "        knowledge = {\"perguntas_respostas\": {}}\n",
    "        for filename in os.listdir(self.base_path):\n",
    "            if filename.endswith('.json'):\n",
    "                with open(os.path.join(self.base_path, filename), 'r') as f:\n",
    "                    domain_knowledge = json.load(f)\n",
    "                    knowledge[\"perguntas_respostas\"].update(domain_knowledge[\"perguntas_respostas\"])\n",
    "        return knowledge\n",
    "\n",
    "    def add_knowledge(self, domain_name, new_knowledge):\n",
    "        # Adiciona novo conhecimento e salva em arquivo separado\n",
    "        filename = f\"{domain_name}_{datetime.now().strftime('%Y%m%d')}.json\"\n",
    "        filepath = os.path.join(self.base_path, filename)\n",
    "        \n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(new_knowledge, f, indent=2)\n",
    "        \n",
    "        # Atualiza a base de conhecimento em memória\n",
    "        self.knowledge_base[\"perguntas_respostas\"].update(new_knowledge[\"perguntas_respostas\"])\n",
    "\n",
    "def train_model(model_name, knowledge_base, output_dir=\"trained_model\"):\n",
    "    \"\"\"Treina ou continua o treinamento do modelo com nova base de conhecimento.\"\"\"\n",
    "    # Carrega modelo e tokenizer\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # Define o pad_token\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Prepara dataset\n",
    "    dataset = KnowledgeBaseDataset(knowledge_base, tokenizer)\n",
    "    \n",
    "    # Configurações de treinamento\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=4,\n",
    "        save_steps=100,\n",
    "        save_total_limit=2,\n",
    "        logging_dir=f\"{output_dir}/logs\",\n",
    "        learning_rate=2e-5,\n",
    "    )\n",
    "    \n",
    "    # Inicializa trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset,\n",
    "    )\n",
    "    \n",
    "    # Treina o modelo\n",
    "    trainer.train()\n",
    "    \n",
    "    # Salva o modelo e tokenizer\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "# Exemplo de uso\n",
    "def main():\n",
    "    # Inicializa o gerenciador de conhecimento\n",
    "    knowledge_manager = KnowledgeManager()\n",
    "    \n",
    "    # Adiciona conhecimento inicial (estagiário)\n",
    "    calculo_knowledge = {\n",
    "        \"perguntas_respostas\": {\n",
    "            \"geral\": {\n",
    "                \"pergunta\": \"O que é o objeto estagiario e qual sua função principal?\",\n",
    "                \"resposta\": \"O objeto estagiario retorna os dados da matrícula...\"\n",
    "            }\n",
    "            # ... resto do conhecimento do estagiário\n",
    "        }\n",
    "    }\n",
    "    knowledge_manager.add_knowledge(\"calculo\", calculo_knowledge)\n",
    "    \n",
    "    # Mais tarde, adiciona conhecimento sobre cálculo\n",
    "    estagiario_knowledge = {\n",
    "    \"perguntas_respostas\": {\n",
    "        \"geral\": {\n",
    "        \"pergunta\": \"O que é o objeto estagiario e qual sua função principal?\",\n",
    "        \"resposta\": \"O objeto estagiario retorna os dados da matrícula que sejam do tipo estagiário no cálculo. Ele permite acessar todas as informações relacionadas ao cadastro e configurações do estagiário.\"\n",
    "        },\n",
    "        \"dados_pagamento\": {\n",
    "        \"pergunta\": \"Como posso acessar as informações bancárias e de pagamento do estagiário?\",\n",
    "        \"resposta\": {\n",
    "            \"descricao\": \"Existem várias propriedades relacionadas ao pagamento:\",\n",
    "            \"variaveis\": [\n",
    "            \"formaPagamento: Retorna a forma de pagamento do estagiário\",\n",
    "            \"bancoPagamento: Retorna o banco de pagamento\",\n",
    "            \"agenciaPagamento: Retorna a agência de pagamento\",\n",
    "            \"bolsaEstudos: Retorna o valor da bolsa de estudos (remuneração)\"\n",
    "            ],\n",
    "            \"exemplo\": {\n",
    "            \"forma_pagamento\": \"if (estagiario.formaPagamento == FormaPagamento.DINHEIRO) { imprimir 'Forma de pagamento é em dinheiro'; }\",\n",
    "            \"dados_bancarios\": \"String bancoPagamento = estagiario.bancoPagamento;\\nString agenciaPagamento = estagiario.agenciaPagamento;\"\n",
    "            }\n",
    "        }\n",
    "        },\n",
    "        \"dados_salariais\": {\n",
    "        \"pergunta\": \"Como posso obter informações sobre o plano salarial do estagiário?\",\n",
    "        \"resposta\": {\n",
    "            \"descricao\": \"O objeto estagiario possui várias propriedades relacionadas à estrutura salarial:\",\n",
    "            \"variaveis\": [\n",
    "            \"grupoFuncional: Retorna o grupo funcional\",\n",
    "            \"planoSalarial: Retorna o plano salarial\",\n",
    "            \"classeSalarial: Retorna a classe salarial\",\n",
    "            \"nivelSalarial: Retorna o nível salarial\",\n",
    "            \"nivelSalarialCoeficiente: Indica se o nível salarial possui coeficiente\"\n",
    "            ],\n",
    "            \"exemplos\": {\n",
    "            \"acesso_basico\": \"String planoSalarial = estagiario.planoSalarial;\\nString classeSalarial = estagiario.classeSalarial;\",\n",
    "            \"verificacao_coeficiente\": \"Boolean nivelSalarialCoeficiente = estagiario.nivelSalarialCoeficiente;\"\n",
    "            }\n",
    "        }\n",
    "        },\n",
    "        \"periodo_estagio\": {\n",
    "        \"pergunta\": \"Como verificar as datas e períodos relacionados ao estágio?\",\n",
    "        \"resposta\": {\n",
    "            \"descricao\": \"Existem várias propriedades para controle de datas do estágio:\",\n",
    "            \"variaveis\": [\n",
    "            \"dataInicioEstagio: Data de início do estágio\",\n",
    "            \"dataFinalEstagio: Data final do estágio\",\n",
    "            \"dataProrrogacao: Data da prorrogação do estágio\"\n",
    "            ],\n",
    "            \"exemplo\": {\n",
    "            \"verificacao_data\": \"Date dataInicioEstagio = estagiario.dataInicioEstagio;\\nDate dataFinalEstagio = estagiario.dataFinalEstagio;\",\n",
    "            \"verificacao_prorrogacao\": \"if (estagiario.dataProrrogacao != null) { Date dataProrrogacao = estagiario.dataProrrogacao; }\"\n",
    "            }\n",
    "        }\n",
    "        },\n",
    "        \"ferias_beneficios\": {\n",
    "        \"pergunta\": \"Como consultar informações sobre férias e benefícios do estagiário?\",\n",
    "        \"resposta\": {\n",
    "            \"descricao\": \"O objeto possui propriedades específicas para férias e benefícios:\",\n",
    "            \"variaveis\": [\n",
    "            \"recebeDecimoTerceiro: Indica se recebe 13º conforme configuração do cargo\",\n",
    "            \"diasDireitoFerias: Dias de direito de férias conforme configuração\",\n",
    "            \"mesesAquisicaoFerias: Meses para aquisição de férias\"\n",
    "            ],\n",
    "            \"exemplos\": {\n",
    "            \"verificacao_13\": \"Boolean recebeDecimoTerceiro = estagiario.recebeDecimoTerceiro;\",\n",
    "            \"consulta_ferias\": \"int diasDireitoFerias = estagiario.diasDireitoFerias;\\nint mesesAquisicaoFerias = estagiario.mesesAquisicaoFerias;\"\n",
    "            }\n",
    "        }\n",
    "        },\n",
    "        \"carga_horaria\": {\n",
    "        \"pergunta\": \"Como verificar a carga horária do estagiário?\",\n",
    "        \"resposta\": {\n",
    "            \"descricao\": \"Use a propriedade quantidadeHorasMes\",\n",
    "            \"exemplo\": \"BigDecimal quantidadeHorasMes = estagiario.quantidadeHorasMes;\\nif (quantidadeHorasMes < BigDecimal.valueOf(100)) {\\n    imprimir 'Quantidade de horas mês é menor que 100';\\n}\",\n",
    "            \"observacao\": \"O valor retornado é do tipo BigDecimal para maior precisão no cálculo\"\n",
    "        }\n",
    "        },\n",
    "        \"dados_organizacionais\": {\n",
    "        \"pergunta\": \"Como obter informações sobre a localização organizacional do estagiário?\",\n",
    "        \"resposta\": {\n",
    "            \"descricao\": \"Use a propriedade descricaoOrganograma\",\n",
    "            \"exemplo\": \"String descricaoOrganograma = estagiario.descricaoOrganograma;\",\n",
    "            \"observacao\": \"Retorna a descrição completa do organograma onde o estagiário está alocado\"\n",
    "        }\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "    knowledge_manager.add_knowledge(\"estagiario\", estagiario_knowledge)\n",
    "    \n",
    "    # Treina o modelo com todo o conhecimento\n",
    "    model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "    model, tokenizer = train_model(model_name, knowledge_manager.knowledge_base)\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, tokenizer = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
